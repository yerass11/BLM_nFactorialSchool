# BLM_nfactorialSchool
Task II of the qualifying stage of the Nfactorial Incubator 2023

### **Биграмма** букв - это пара букв, которые стоят рядом в слове. Например, в слове "кот" биграммы это "^к", "ко", "от", и "т$" (*^ и $ — начало и конец слова.*)

Мы используем биграммы букв, чтобы лучше понимать, какие пары букв чаще всего встречаются в словах. Это может быть полезно, например, для предсказания следующего слова в предложении или определения языка, на котором написан текст. 

Представьте что вам нужно придумать имя для вашего ребенка. У вас есть список уже существующих имен. Ваша задача: придумать **новое имя!**

**Логика модели:**

- Прочитайте данные с файла в структуры данных удобных для высчитывания вероятностей
- Высчитайте вероятность всех существующих биграмм (строим выборку)
- Возьмите букву из выборки которое может придти как первая буква имени (рандомно)
- Продолжать тянуть следующую букву из выборки, таким образом генерируя имя. Это нужно делать пока вы не вытянули конец имени.

**Пользователь**

- Generate function - возможность создавать имя.
- получить таблицу визуализирующие вероятности биграмм

**Бонус**

- использование и оптимизирование с помощью библиотеки **pytorch**
- визуализация таблицы в картинку (подойдет любая библиотека)

**2x Бонус**

Создать нейронную сеть которая учится на выборке. Гугл в помощь!


Код 'сor.py' на Py3 включает в себя следующие функции:

*   MIN_SIZE = 4 - задает значение минимальной длины имени, которое генерируется.
*   ALPHABET = 'abcdefghijklmnopqrstuvwxyz' - задает алфавит, используемый для генерации имени.
*   DATA_FILE = 'names.txt' - задает имя файла, содержащего имена, на основе которых строится языковая модель.


*   __init__() - инициализирует объект модели, создавая два пустых словаря self.count и self.context, которые будут использоваться для подсчета частот биграмм и создания матрицы переходов.
*   update(name: str)' - обновляет модель на основе нового имени, добавляя в словари self.count и self.context информацию о частоте биграмм и матрице переходов соответственно.
*   all_bigrams(word: str) - возвращает список всех биграмм в слове word.
*   getting_next(context: str) - возвращает следующий символ, основываясь на заданном контексте.
*   generate_name() - генерирует новое имя на основе модели.
*   get_probability(char: str) - возвращает словарь с частотами символов, следующих за символом char.
*   get_all_probabilities() - возвращает словарь с информацией о частотах всех биграмм, которые могут быть созданы из символов алфавита.



*   Далее определена функция create_language_model(data: list), которая создает объект класса BigramLanguageModel, используя данные, содержащиеся в списке data.

Также есть две функции для визуализации результатов:

*   table() - создает таблицу в формате DataFrame из частот биграмм.
*   graph() - создает гистограмму, показывающую частоты символов, следующих за каждой буквой алфавита.